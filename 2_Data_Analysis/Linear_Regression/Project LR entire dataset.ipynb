{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pyspark\n","from pyspark.sql import SparkSession\n","import numpy as np\n","import pandas as pd\n","from pyspark.ml.regression import LinearRegression\n","from pyspark.ml.feature import (VectorAssembler, VectorIndexer)\n","from pyspark.sql.types import IntegerType"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Warning: Ignoring non-Spark config property: hive.server2.thrift.port\n","Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","22/04/10 21:18:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]}],"source":["spark = SparkSession.builder.appName(\"spark\").config('spark.driver.memory', '32g').config(\"hive.server2.thrift.port\", 10000).config(\"spark.sql.hive.thriftServer.singleSession\", True).enableHiveSupport().getOrCreate()"]},{"cell_type":"code","execution_count":3,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b0586145-675b-46d0-bb60-a50a1cd6a318","showTitle":false,"title":""}},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 1:======================================================>(192 + 2) / 194]\r"]},{"name":"stdout","output_type":"stream","text":["root\n"," |-- ID: integer (nullable = true)\n"," |-- SPEED: double (nullable = true)\n"," |-- TRAVEL_TIME: integer (nullable = true)\n"," |-- STATUS: integer (nullable = true)\n"," |-- DATA_AS_OF: string (nullable = true)\n"," |-- LINK_ID: integer (nullable = true)\n"," |-- LINK_POINTS: string (nullable = true)\n"," |-- ENCODED_POLY_LINE: string (nullable = true)\n"," |-- ENCODED_POLY_LINE_LVLS: string (nullable = true)\n"," |-- OWNER: string (nullable = true)\n"," |-- TRANSCOM_ID: integer (nullable = true)\n"," |-- BOROUGH: string (nullable = true)\n"," |-- LINK_NAME: string (nullable = true)\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df1 = spark.read.format(\"csv\").option(\"header\", \"true\").option('inferSchema', \"true\").load(\"/Users/minoseah629/Repos/AIT614Project/Data_Preparation/Python/raw_data/raw.csv\") \n","df1.printSchema()"]},{"cell_type":"code","execution_count":4,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"962e6af5-df0c-4fc7-a85d-1d31556f83c4","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql.functions import to_timestamp\n","df1 = df1.withColumn(\"DATA_AS_OF\", to_timestamp(\"DATA_AS_OF\", 'MM/dd/yyyy hh:mm:ss a'))\n","df1 = df1.withColumnRenamed('DATA_AS_OF','timedate')\n","df1.createOrReplaceTempView('dataset')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+-----------+-------------------+-------+----+------+-------+----+-----+---+-----------+\n","|SPEED|travel_time|           timedate|LINK_ID|hour|minute|weekday|year|month|day|day_of_year|\n","+-----+-----------+-------------------+-------+----+------+-------+----+-----+---+-----------+\n","|44.11|         48|2021-09-22 17:08:11|4616204|  17|     8|      2|2021|    9| 22|        265|\n","|11.18|        515|2021-09-22 17:08:11|4616206|  17|     8|      2|2021|    9| 22|        265|\n","| 5.59|        917|2021-09-22 17:08:11|4616210|  17|     8|      2|2021|    9| 22|        265|\n","|24.23|        117|2021-09-22 17:08:11|4616211|  17|     8|      2|2021|    9| 22|        265|\n","|53.43|        140|2021-09-22 17:08:11|4616215|  17|     8|      2|2021|    9| 22|        265|\n","|  0.0|          0|2021-09-22 17:08:11|4616216|  17|     8|      2|2021|    9| 22|        265|\n","|  0.0|          0|2021-09-22 17:08:11|4616217|  17|     8|      2|2021|    9| 22|        265|\n","|50.33|         42|2021-09-22 17:08:11|4616218|  17|     8|      2|2021|    9| 22|        265|\n","|37.28|         57|2021-09-22 17:08:11|4616219|  17|     8|      2|2021|    9| 22|        265|\n","|  0.0|          0|2021-09-22 17:08:11|4616228|  17|     8|      2|2021|    9| 22|        265|\n","|16.77|        328|2021-09-22 17:08:11|4616239|  17|     8|      2|2021|    9| 22|        265|\n","|16.77|        318|2021-09-22 17:08:11|4616241|  17|     8|      2|2021|    9| 22|        265|\n","| 49.7|         93|2021-09-22 17:08:11|4616246|  17|     8|      2|2021|    9| 22|        265|\n","| 49.7|        150|2021-09-22 17:08:11|4616247|  17|     8|      2|2021|    9| 22|        265|\n","|18.01|        249|2021-09-22 17:08:11|4616250|  17|     8|      2|2021|    9| 22|        265|\n","|31.68|        174|2021-09-22 17:08:11|4616252|  17|     8|      2|2021|    9| 22|        265|\n","|26.09|         96|2021-09-22 17:08:11|4616253|  17|     8|      2|2021|    9| 22|        265|\n","|14.29|        607|2021-09-22 17:08:11|4616259|  17|     8|      2|2021|    9| 22|        265|\n","|47.84|         93|2021-09-22 17:08:11|4616260|  17|     8|      2|2021|    9| 22|        265|\n","|47.84|        156|2021-09-22 17:08:11|4616261|  17|     8|      2|2021|    9| 22|        265|\n","+-----+-----------+-------------------+-------+----+------+-------+----+-----+---+-----------+\n","only showing top 20 rows\n","\n"]}],"source":["df2 = spark.sql('select SPEED, travel_time, timedate,LINK_ID,hour(timedate) `hour`,minute(timedate) `minute`,weekday(timedate) `weekday`,year(timedate) `year`,month(timedate) `month`,day(timedate) `day`,dayofyear(timedate) as `day_of_year` from dataset')\n","df2.show()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["assembler = VectorAssembler(inputCols=['SPEED','hour','minute','weekday','year','month','day','day_of_year'], outputCol='features')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+-----------+-------------------+-------+----+------+-------+----+-----+---+-----------+--------------------+\n","|SPEED|travel_time|           timedate|LINK_ID|hour|minute|weekday|year|month|day|day_of_year|            features|\n","+-----+-----------+-------------------+-------+----+------+-------+----+-----+---+-----------+--------------------+\n","|44.11|         48|2021-09-22 17:08:11|4616204|  17|     8|      2|2021|    9| 22|        265|[44.11,17.0,8.0,2...|\n","|11.18|        515|2021-09-22 17:08:11|4616206|  17|     8|      2|2021|    9| 22|        265|[11.18,17.0,8.0,2...|\n","| 5.59|        917|2021-09-22 17:08:11|4616210|  17|     8|      2|2021|    9| 22|        265|[5.59,17.0,8.0,2....|\n","|24.23|        117|2021-09-22 17:08:11|4616211|  17|     8|      2|2021|    9| 22|        265|[24.23,17.0,8.0,2...|\n","|53.43|        140|2021-09-22 17:08:11|4616215|  17|     8|      2|2021|    9| 22|        265|[53.43,17.0,8.0,2...|\n","+-----+-----------+-------------------+-------+----+------+-------+----+-----+---+-----------+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["df_out = assembler.transform(df2)\n","\n","df_out.show(5)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+-----+\n","|            features|label|\n","+--------------------+-----+\n","|[44.11,17.0,8.0,2...|   48|\n","|[11.18,17.0,8.0,2...|  515|\n","|[5.59,17.0,8.0,2....|  917|\n","|[24.23,17.0,8.0,2...|  117|\n","|[53.43,17.0,8.0,2...|  140|\n","|[0.0,17.0,8.0,2.0...|    0|\n","|[0.0,17.0,8.0,2.0...|    0|\n","|[50.33,17.0,8.0,2...|   42|\n","|[37.28,17.0,8.0,2...|   57|\n","|[0.0,17.0,8.0,2.0...|    0|\n","|[16.77,17.0,8.0,2...|  328|\n","|[16.77,17.0,8.0,2...|  318|\n","|[49.7,17.0,8.0,2....|   93|\n","|[49.7,17.0,8.0,2....|  150|\n","|[18.01,17.0,8.0,2...|  249|\n","|[31.68,17.0,8.0,2...|  174|\n","|[26.09,17.0,8.0,2...|   96|\n","|[14.29,17.0,8.0,2...|  607|\n","|[47.84,17.0,8.0,2...|   93|\n","|[47.84,17.0,8.0,2...|  156|\n","+--------------------+-----+\n","only showing top 20 rows\n","\n"]}],"source":["from pyspark.sql.functions import col\n","clean_df = df_out.select(['features', 'travel_time'])\n","clean_df = df_out.select(['features', col('travel_time').alias('label')])\n","clean_df.show()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["train, test = clean_df.randomSplit([0.7,0.3], seed= 41)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["lr_model = LinearRegression(featuresCol='features',labelCol='label')"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["22/04/10 21:32:20 WARN Instrumentation: [c46dc89e] regParam is zero, which might cause numerical instability and overfitting.\n","22/04/10 21:32:28 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n","22/04/10 21:32:28 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n","22/04/10 21:34:06 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n","                                                                                \r"]}],"source":["fit_model = lr_model.fit(train)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["test_results = fit_model.evaluate(test)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["0.01809471959488307"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["test_results.r2"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+-----------+-------------------+-------+----+------+-------+----+-----+---+-----------+--------------------+\n","|SPEED|travel_time|           timedate|LINK_ID|hour|minute|weekday|year|month|day|day_of_year|            features|\n","+-----+-----------+-------------------+-------+----+------+-------+----+-----+---+-----------+--------------------+\n","|44.11|         48|2021-09-22 17:08:11|4616204|  17|     8|      2|2021|    9| 22|        265|[48.0,17.0,8.0,2....|\n","|11.18|        515|2021-09-22 17:08:11|4616206|  17|     8|      2|2021|    9| 22|        265|[515.0,17.0,8.0,2...|\n","| 5.59|        917|2021-09-22 17:08:11|4616210|  17|     8|      2|2021|    9| 22|        265|[917.0,17.0,8.0,2...|\n","|24.23|        117|2021-09-22 17:08:11|4616211|  17|     8|      2|2021|    9| 22|        265|[117.0,17.0,8.0,2...|\n","|53.43|        140|2021-09-22 17:08:11|4616215|  17|     8|      2|2021|    9| 22|        265|[140.0,17.0,8.0,2...|\n","+-----+-----------+-------------------+-------+----+------+-------+----+-----+---+-----------+--------------------+\n","only showing top 5 rows\n","\n","+--------------------+-----+\n","|            features|label|\n","+--------------------+-----+\n","|[48.0,17.0,8.0,2....|44.11|\n","|[515.0,17.0,8.0,2...|11.18|\n","|[917.0,17.0,8.0,2...| 5.59|\n","|[117.0,17.0,8.0,2...|24.23|\n","|[140.0,17.0,8.0,2...|53.43|\n","|[0.0,17.0,8.0,2.0...|  0.0|\n","|[0.0,17.0,8.0,2.0...|  0.0|\n","|[42.0,17.0,8.0,2....|50.33|\n","|[57.0,17.0,8.0,2....|37.28|\n","|[0.0,17.0,8.0,2.0...|  0.0|\n","|[328.0,17.0,8.0,2...|16.77|\n","|[318.0,17.0,8.0,2...|16.77|\n","|[93.0,17.0,8.0,2....| 49.7|\n","|[150.0,17.0,8.0,2...| 49.7|\n","|[249.0,17.0,8.0,2...|18.01|\n","|[174.0,17.0,8.0,2...|31.68|\n","|[96.0,17.0,8.0,2....|26.09|\n","|[607.0,17.0,8.0,2...|14.29|\n","|[93.0,17.0,8.0,2....|47.84|\n","|[156.0,17.0,8.0,2...|47.84|\n","+--------------------+-----+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["22/04/10 21:42:40 WARN Instrumentation: [65979abd] regParam is zero, which might cause numerical instability and overfitting.\n","                                                                                \r"]},{"data":{"text/plain":["0.03312473743579136"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["assembler1 = VectorAssembler(inputCols=['travel_time','hour','minute','weekday','year','month','day','day_of_year'], outputCol='features')\n","df_out1 = assembler1.transform(df2)\n","\n","df_out1.show(5)\n","from pyspark.sql.functions import col\n","clean_df1 = df_out1.select(['features', 'speed'])\n","clean_df1 = df_out1.select(['features', col('speed').alias('label')])\n","clean_df1.show()\n","train1, test1 = clean_df1.randomSplit([0.7,0.3], seed= 41)\n","lr_model1 = LinearRegression(featuresCol='features',labelCol='label')\n","fit_model1 = lr_model1.fit(train1)\n","test_results1 = fit_model1.evaluate(test1)\n","test_results1.r2"]},{"cell_type":"code","execution_count":1,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"ce3bf3a9-1656-4777-92d8-96e1ac733cb9","showTitle":false,"title":""}},"outputs":[{"ename":"NameError","evalue":"name 'spark' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/Users/minoseah629/Repos/AIT614Project/linear regression/Project LR entire dataset.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/minoseah629/Repos/AIT614Project/linear%20regression/Project%20LR%20entire%20dataset.ipynb#ch0000010?line=0'>1</a>\u001b[0m spark\u001b[39m.\u001b[39mstop()\n","\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"]}],"source":["spark.stop()"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"Project LR","notebookOrigID":349403358739354,"widgets":{}},"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"},"kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"}},"nbformat":4,"nbformat_minor":0}
