{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install findspark\n",
    "#/usr/local/opt/apache-spark/libexec/sbin\n",
    "#./start-thriftserver.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: hive.server2.thrift.port\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/Cellar/apache-spark/3.2.1/libexec/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/12 11:09:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"spark\").config('spark.driver.memory', '32g').config(\"hive.server2.thrift.port\", 10000).config(\"spark.sql.hive.thriftServer.singleSession\", True).enableHiveSupport().getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      " |-- TravelTime: integer (nullable = true)\n",
      " |-- Status: integer (nullable = true)\n",
      " |-- timedate: string (nullable = true)\n",
      " |-- LinkId: integer (nullable = true)\n",
      " |-- LinkPoints: string (nullable = true)\n",
      " |-- EncodedLinkPoints: string (nullable = true)\n",
      " |-- EncodedPolyLineLvls: string (nullable = true)\n",
      " |-- Owner: string (nullable = true)\n",
      " |-- TranscomId: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Link_Name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType,TimestampType\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ID\", IntegerType()),\n",
    "    StructField(\"Speed\", DoubleType()),\n",
    "    StructField(\"TravelTime\", IntegerType()),\n",
    "    StructField(\"Status\", IntegerType()),\n",
    "    StructField(\"timedate\", StringType()),\n",
    "    StructField(\"LinkId\", IntegerType()),\n",
    "    StructField(\"LinkPoints\", StringType()),\n",
    "    StructField(\"EncodedLinkPoints\", StringType()),\n",
    "    StructField(\"EncodedPolyLineLvls\", StringType()),\n",
    "    StructField(\"Owner\", StringType()),\n",
    "    StructField(\"TranscomId\", IntegerType()),\n",
    "    StructField(\"Borough\", StringType()),\n",
    "    StructField(\"Link_Name\", StringType())    \n",
    "])\n",
    "\n",
    "df1 = spark.read.format(\"csv\").option(\"header\", \"false\").schema(schema).load(\"file:/Users/minoseah629/Desktop/ait614/*5M/*.csv\")\n",
    "df1.printSchema()\n",
    "# .option(\"inferSchema\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58892322"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df1.withColumn(\"timedate\", to_timestamp(\"timedate\", 'MM/dd/yyyy hh:mm:ss a'))\n",
    "df1.na.drop()\n",
    "df1.createOrReplaceTempView(\"dataset\")\n",
    "\n",
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2017'\n",
    "start = year+'-01-01'\n",
    "end = year+'-12-31'\n",
    "query = \"select ID,Speed,TravelTime,Status,timedate,LinkId,LinkPoints,EncodedLinkPoints,EncodedPolyLineLvls,Owner,TranscomId,Borough,Link_Name from dataset\"\n",
    "where = \"where timedate >= '\"+start+\"' and timedate <= '\"+end+\"' order by timedate asc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2017 = spark.sql(query + \" \"+where)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "y2017.write.format('csv').mode('overwrite').save('file:/Users/minoseah629/Desktop/ait614/year'+year+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView(\"dataset\")\n",
    "linkpoints = spark.sql(\"select count(EncodedLinkPoints),EncodedLinkPoints from dataset where id = 148 group by EncodedLinkPoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+------+-------------------+-------+--------------------+--------------------+--------------------+--------------------+----------+-------------+--------------------+\n",
      "| ID|Speed|TravelTime|Status|           timedate| LinkId|          LinkPoints|   EncodedLinkPoints| EncodedPolyLineLvls|               Owner|TranscomId|      Borough|           Link_Name|\n",
      "+---+-----+----------+------+-------------------+-------+--------------------+--------------------+--------------------+--------------------+----------+-------------+--------------------+\n",
      "|190|40.38|       105|     0|2022-01-01 00:03:10|4620332|40.84671,-73.9319...|}zhxFryfbMfC_J~Bq...|           BBBBBBBBB|         PA-GWBridge|   4620332|        Bronx|CBE W MORRIS AVE ...|\n",
      "|186|52.81|       157|     0|2022-01-01 00:03:10|4620315|40.84667,-73.9318...|uzhxFfyfbMcCbIsGf...|      BBBBBBBBBBBBBB|         PA-GWBridge|   4620315|        Bronx|CBE W L/LE V AMST...|\n",
      "|324| 8.69|       627|  -101|2022-01-01 00:03:10|4329473|40.7578106,-73.99...|iowwF~nsbMoObg@yH...|                BBBB|  PA -Lincoln Tunnel|   4329473|    Manhattan|LINCOLN TUNNEL E ...|\n",
      "|195|55.92|       149|     0|2022-01-01 00:03:10|4620310|40.84653,-73.9320...|yyhxFdzfbM_CvH{G`...|      BBBBBBBBBBBBBB|         PA-GWBridge|   4620310|        Bronx|CBE W U/LEV AMSTE...|\n",
      "|345| 7.45|       567|  -101|2022-01-01 00:03:10|4620314|40.85526,-73.9185...|kpjxFdfdbMfObMjOb...|     BBBBBBBBBBBBBBB|         NYC_DOT_LIC|   4620314|        Bronx|MDE S HARLEM RIVE...|\n",
      "|440|50.95|       151|     0|2022-01-01 00:03:10|4329483|40.5264504,-74.27...|iijvFpzhdMxCoLnAo...|     BBBBBBBBBBBBBBB|         NYC_DOT_LIC|   4329483|Staten Island|WSE S TYRELLAN AV...|\n",
      "|265|39.14|       188|     0|2022-01-01 00:03:10|4620298|40.8462505,-73.93...|axhxF~zfbMkCfHeHf...|      BBBBBBBBBBBBBB|         PA-GWBridge|   4620298|    Manhattan|GWB E LOWER LEVEL...|\n",
      "|191|55.92|        77|     0|2022-01-01 00:03:10|4620331|40.8465405,-73.93...|{yhxFbzfbMtA}FfDy...|          BBBBBBBBBB|         PA-GWBridge|   4620331|        Bronx|CBE W MORRIS AVE ...|\n",
      "|344| 20.5|       218|     0|2022-01-01 00:03:10|4620330|40.85513,-73.9186...|qojxFpfdbMrN\\\\\\\\\\...|     BBBBBBBBBBBBBBB|         NYC_DOT_LIC|   4620330|        Bronx|MDE S HARLEM RIVE...|\n",
      "|325| 9.32|       569|  -101|2022-01-01 00:03:10|4329472|40.75829,-73.9975...|irwwFpssbMyLlb@wH...|                BBBB|  PA -Lincoln Tunnel|   4329472|    Manhattan|LINCOLN TUNNEL E ...|\n",
      "|329|  0.0|         0|  -101|2022-01-01 00:03:10|4329508|40.75766,-73.9968...|knwwFlosbMcP`g@yH...|                BBBB|  PA -Lincoln Tunnel|   4329508|    Manhattan|LINCOLN TUNNEL W ...|\n",
      "|364|41.01|       134|  -101|2022-01-01 00:04:03|4456511|40.745726,-73.973...|wcuwF\\\\\\\\\\\\\\\\\\\\\\\\...|         BBBBBBBBBBB|         NYC_DOT_LIC|   4456511|    Manhattan|QMT E Manhattan S...|\n",
      "|395|47.84|       169|     0|2022-01-01 00:04:03|4456476|40.7723,-73.91983...|{izwF\\\\\\\\\\\\\\\\\\\\\\\\...|BBBBBBBBBBBBBBBBB...|MTA Bridges & Tun...|   4456476|       Queens|TBB N QUEENS ANCH...|\n",
      "|298|54.05|        53|     0|2022-01-01 00:04:03|4456498|40.8251205,-73.83...|_tdxFhdtaMjCOxHMv...|             BBBBBBB|         NYC_DOT_LIC|   4456498|        Bronx|HRP S Lafayette A...|\n",
      "|213|16.15|       144|     0|2022-01-01 00:04:03|4456450|40.80069,-73.9287...|i{_xFzefbMyBvGUlA...|BBBBBBBBBBBBBBBBB...|MTA Bridges & Tun...|   4456450|    Manhattan|FDR N - TBB E 116...|\n",
      "|398|47.84|       156|     0|2022-01-01 00:04:03|4456481|40.77223,-73.9199...|mizwFrndbM_HvKuC~...|BBBBBBBBBBBBBBBBB...|MTA Bridges & Tun...|   4456481|       Queens|TBB S MANHATTAN L...|\n",
      "|140| 6.21|       455|     0|2022-01-01 00:04:03|4456479|40.79789,-73.9198...|yi_xFfndbMb@^Xb@T...|     BBBBBBBBBBBBBBB|MTA Bridges & Tun...|   4456479|       Queens|BE S TBB EXIT RAM...|\n",
      "|365|41.63|       132|     0|2022-01-01 00:04:03|4456510|40.741534,-73.954...|qitwFzckbMDhDkEh]...|           BBBBBBBBB|         NYC_DOT_LIC|   4456510|       Queens|QMT W Toll Plaza ...|\n",
      "|347|50.95|       136|     0|2022-01-01 00:04:03|4456477|40.77223,-73.9199...|mizwFrndbM_HvKuC~...|BBBBBBBBBBBBBBBBB...|MTA Bridges & Tun...|   4456477|       Queens|MDE S TBB EXIT RA...|\n",
      "|349|  0.0|         0|  -101|2022-01-01 00:04:03|4329499|40.6309004,-74.14...|cv~vFpqpcMqI_@_Jo...|BBBBBBBBBBBBBBBBB...|         NYC_DOT_LIC|   4329499|Staten Island|MLK N WALKER STRE...|\n",
      "+---+-----+----------+------+-------------------+-------+--------------------+--------------------+--------------------+--------------------+----------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y2021.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|max(length(_c6))|\n",
      "+----------------+\n",
      "|             255|\n",
      "+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.createOrReplaceTempView(\"noschema\")\n",
    "spark.sql(\"select max(length(_c6)) from noschema\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
