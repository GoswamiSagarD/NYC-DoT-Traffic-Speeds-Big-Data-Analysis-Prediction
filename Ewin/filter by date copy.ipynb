{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install findspark\n",
    "\n",
    "#/usr/local/opt/apache-spark/libexec/sbin\n",
    "#./start-thriftserver.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: hive.server2.thrift.port\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/30 16:30:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/30 16:30:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"spark\")\\\n",
    "    .config('spark.driver.memory', '32g')\\\n",
    "    .config(\"hive.server2.thrift.port\", 10000)\\\n",
    "    .config(\"spark.sql.hive.thriftServer.singleSession\", True)\\\n",
    "    .enableHiveSupport()\\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      " |-- TravelTime: integer (nullable = true)\n",
      " |-- timedate: timestamp (nullable = true)\n",
      " |-- LinkId: integer (nullable = true)\n",
      " |-- LinkPoints: string (nullable = true)\n",
      " |-- Owner: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Link_Name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType,TimestampType\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ID\", IntegerType()),\n",
    "    StructField(\"Speed\", DoubleType()),\n",
    "    StructField(\"TravelTime\", IntegerType()),\n",
    "    StructField(\"Status\", IntegerType()),\n",
    "    StructField(\"timedate\", StringType()),\n",
    "    StructField(\"LinkId\", IntegerType()),\n",
    "    StructField(\"LinkPoints\", StringType()),\n",
    "    StructField(\"EncodedLinkPoints\", StringType()),\n",
    "    StructField(\"EncodedPolyLineLvls\", StringType()),\n",
    "    StructField(\"Owner\", StringType()),\n",
    "    StructField(\"TranscomId\", IntegerType()),\n",
    "    StructField(\"Borough\", StringType()),\n",
    "    StructField(\"Link_Name\", StringType())\n",
    "])\n",
    "\n",
    "schema1 = \"ID bigint, Speed float, TravelTime int, Status int, TimeDate string, LinkId int, LinkPoints string, EncodedLinkPoints string, EncodedPolyLineLvls string, Owner string, TranscomId int, Borough string,Link_Name string\"\n",
    "df2 = spark.read.format(\"csv\").option(\"header\", \"true\").schema(schema).load(\"file:/Users/minoseah629/Downloads/DOT_Traffic_Speeds_NBE.csv\")\n",
    "df2 = df2.withColumn(\"timedate\", to_timestamp(\"timedate\", 'MM/dd/yyyy hh:mm:ss a'))\n",
    "df2 = df2.na.drop()\n",
    "df2 = df2.drop(*(\"Status\",\"EncodedLinkPoints\",\"EncodedPolyLineLvls\",\"TranscomId\"))\n",
    "df2.printSchema()\n",
    "df2.createOrReplaceTempView(\"dataset\")\n",
    "# .option(\"inferSchema\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/30 16:55:34 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: ID, SPEED, TRAVEL_TIME, STATUS, DATA_AS_OF, LINK_ID, LINK_POINTS, ENCODED_POLY_LINE, ENCODED_POLY_LINE_LVLS, OWNER, TRANSCOM_ID, BOROUGH, LINK_NAME\n",
      " Schema: ID, Speed, TravelTime, Status, timedate, LinkId, LinkPoints, EncodedLinkPoints, EncodedPolyLineLvls, Owner, TranscomId, Borough, Link_Name\n",
      "Expected: TravelTime but found: TRAVEL_TIME\n",
      "CSV file: file:///Users/minoseah629/Downloads/DOT_Traffic_Speeds_NBE.csv\n",
      "[Stage 11:===================================================>  (184 + 8) / 192]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------------------+\n",
      "| id|speed|           timedate|\n",
      "+---+-----+-------------------+\n",
      "|445| 3.73|2017-05-05 09:49:55|\n",
      "|190|44.12|2017-05-05 09:49:47|\n",
      "|417|37.28|2017-05-05 09:49:55|\n",
      "|141|32.93|2017-05-05 09:49:55|\n",
      "|451|19.88|2017-05-05 09:49:55|\n",
      "|364| 3.73|2017-05-05 09:49:55|\n",
      "|398|31.07|2017-05-05 09:49:55|\n",
      "|313|  0.0|2017-02-08 17:55:05|\n",
      "|311|29.83|2017-05-05 09:50:33|\n",
      "|298|49.09|2017-05-05 09:49:55|\n",
      "|344|31.69|2017-05-05 09:49:47|\n",
      "|119| 3.73|2017-05-05 09:49:55|\n",
      "|213|34.18|2017-05-05 09:49:55|\n",
      "|395|11.81|2017-05-05 09:49:55|\n",
      "|380|39.77|2017-05-05 09:49:55|\n",
      "|148|  0.0|2017-04-27 14:07:03|\n",
      "|157|  0.0|2017-04-27 14:07:03|\n",
      "|316|  0.0|2017-04-11 15:17:02|\n",
      "|347|32.93|2017-05-05 09:49:55|\n",
      "|164|14.29|2017-05-05 09:49:55|\n",
      "+---+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data2022 = spark.sql(\"select id, speed, timedate from dataset where year(timedate) >= 2017 order by year(timedate) asc\")\n",
    "data2022.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/23 22:48:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: ID, SPEED, TRAVEL_TIME, STATUS, DATA_AS_OF, LINK_ID, LINK_POINTS, ENCODED_POLY_LINE, ENCODED_POLY_LINE_LVLS, OWNER, TRANSCOM_ID, BOROUGH, LINK_NAME\n",
      " Schema: ID, Speed, TravelTime, Status, timedate, LinkId, LinkPoints, EncodedLinkPoints, EncodedPolyLineLvls, Owner, TranscomId, Borough, Link_Name\n",
      "Expected: TravelTime but found: TRAVEL_TIME\n",
      "CSV file: file:///Users/minoseah629/Downloads/DOT_Traffic_Speeds_NBE.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|                 col|\n",
      "+---+--------------------+\n",
      "|  1|[\"40.74047,-74.00...|\n",
      "|  2|[\"40.73933,-74.01...|\n",
      "|  3|[\"40.76375,-73.99...|\n",
      "|  4|[\"40.7607,-74.002...|\n",
      "|106|[\"40.77158,-73.99...|\n",
      "|107|[\"40.64289,-74.21...|\n",
      "|108|[\"40.62464,-74.17...|\n",
      "|110|[\"40.5256,-74.230...|\n",
      "|119|[\"40.70631,-74.01...|\n",
      "|122|[\"40.7073904,-74....|\n",
      "|123|[\"40.70738,-74.01...|\n",
      "|124|[\"40.68036,-74.00...|\n",
      "|126|[\"40.8271606,-73....|\n",
      "|126|[\"40.8271606,-73....|\n",
      "|129|[\"40.8240706,-73....|\n",
      "|137|[\"40.8242005,-73....|\n",
      "|140|[\"40.79789,-73.91...|\n",
      "|141|[\"40.772251,-73.9...|\n",
      "|142|[\"40.83037,-73.85...|\n",
      "|145|[\"40.7081105,-73....|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2022.select(col('id'),exp(split(col('Link Points'),' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/30 16:58:00 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: ID, SPEED, TRAVEL_TIME, STATUS, DATA_AS_OF, LINK_ID, LINK_POINTS, ENCODED_POLY_LINE, ENCODED_POLY_LINE_LVLS, OWNER, TRANSCOM_ID, BOROUGH, LINK_NAME\n",
      " Schema: ID, Speed, TravelTime, Status, timedate, LinkId, LinkPoints, EncodedLinkPoints, EncodedPolyLineLvls, Owner, TranscomId, Borough, Link_Name\n",
      "Expected: TravelTime but found: TRAVEL_TIME\n",
      "CSV file: file:///Users/minoseah629/Downloads/DOT_Traffic_Speeds_NBE.csv\n",
      "22/03/30 16:59:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: ID, SPEED, TRAVEL_TIME, STATUS, DATA_AS_OF, LINK_ID, LINK_POINTS, ENCODED_POLY_LINE, ENCODED_POLY_LINE_LVLS, OWNER, TRANSCOM_ID, BOROUGH, LINK_NAME\n",
      " Schema: ID, Speed, TravelTime, Status, timedate, LinkId, LinkPoints, EncodedLinkPoints, EncodedPolyLineLvls, Owner, TranscomId, Borough, Link_Name\n",
      "Expected: TravelTime but found: TRAVEL_TIME\n",
      "CSV file: file:///Users/minoseah629/Downloads/DOT_Traffic_Speeds_NBE.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data2022.write.format('csv').mode('overwrite').save('file:/Users/minoseah629/Desktop/ait614/speed-timedate.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/22 23:33:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: ID, SPEED, TRAVEL_TIME, STATUS, DATA_AS_OF, LINK_ID, LINK_POINTS, ENCODED_POLY_LINE, ENCODED_POLY_LINE_LVLS, OWNER, TRANSCOM_ID, BOROUGH, LINK_NAME\n",
      " Schema: ID, Speed, TravelTime, Status, timedate, LinkId, LinkPoints, EncodedLinkPoints, EncodedPolyLineLvls, Owner, TranscomId, Borough, Link_Name\n",
      "Expected: TravelTime but found: TRAVEL_TIME\n",
      "CSV file: file:///Users/minoseah629/Downloads/DOT_Traffic_Speeds_NBE.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1893262"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2022.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
