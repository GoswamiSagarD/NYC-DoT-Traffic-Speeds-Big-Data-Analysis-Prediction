{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install findspark\n",
    "#/usr/local/opt/apache-spark/libexec/sbin\n",
    "#./start-thriftserver.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: hive.server2.thrift.port\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/02 20:01:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"spark\").config('spark.driver.memory', '32g').config(\"hive.server2.thrift.port\", 10000).config(\"spark.sql.hive.thriftServer.singleSession\", True).enableHiveSupport().getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=====================================================> (187 + 5) / 192]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Speed: double (nullable = true)\n",
      " |-- TravelTime: integer (nullable = true)\n",
      " |-- Status: integer (nullable = true)\n",
      " |-- timedate: timestamp (nullable = true)\n",
      " |-- LinkId: integer (nullable = true)\n",
      " |-- LinkPoints: string (nullable = true)\n",
      " |-- EncodedLinkPoints: string (nullable = true)\n",
      " |-- EncodedPolyLineLvls: string (nullable = true)\n",
      " |-- Owner: string (nullable = true)\n",
      " |-- TranscomId: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Link_Name: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType,TimestampType\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"ID\", IntegerType()),\n",
    "    StructField(\"Speed\", DoubleType()),\n",
    "    StructField(\"TravelTime\", IntegerType()),\n",
    "    StructField(\"Status\", IntegerType()),\n",
    "    StructField(\"timedate\", StringType()),\n",
    "    StructField(\"LinkId\", IntegerType()),\n",
    "    StructField(\"LinkPoints\", StringType()),\n",
    "    StructField(\"EncodedLinkPoints\", StringType()),\n",
    "    StructField(\"EncodedPolyLineLvls\", StringType()),\n",
    "    StructField(\"Owner\", StringType()),\n",
    "    StructField(\"TranscomId\", IntegerType()),\n",
    "    StructField(\"Borough\", StringType()),\n",
    "    StructField(\"Link_Name\", StringType())\n",
    "])\n",
    "\n",
    "schema1 = \"ID bigint, Speed float, TravelTime int, Status int, TimeDate string, LinkId int, LinkPoints string, EncodedLinkPoints string, EncodedPolyLineLvls string, Owner string, TranscomId int, Borough string,Link_Name string\"\n",
    "df2 = spark.read.format(\"csv\").option(\"header\", \"true\").schema(schema).load(\"file:/Users/minoseah629/Downloads/DOT_Traffic_Speeds_NBE.csv\")\n",
    "\n",
    "df2 = df2.withColumn(\"timedate\", to_timestamp(\"timedate\", 'MM/dd/yyyy hh:mm:ss a'))\n",
    "df2.na.drop()\n",
    "df2.createOrReplaceTempView(\"dataset\")\n",
    "df2.count()\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['LINKID', 'LINK_POINTS', 'ENCODED_POLY_LINE', 'ENCODED_POLY_LINE_LVLS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'select LINKID, LINKPOINTS, EncodedLinkPoints, EncodedPolyLineLvls, count(LinkPoints) from dataset group by LINKID, LINKPOINTS, EncodedLinkPoints, EncodedPolyLineLvls'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns1= \"LINKID, LINKPOINTS, EncodedLinkPoints, EncodedPolyLineLvls\"\n",
    "select1 = \"select \"+columns1+\", count(LinkPoints)\"\n",
    "from1 = \" from dataset\"\n",
    "groupby2= \" group by \"+columns1\n",
    "orderby = \" order by year(timedate) desc\"\n",
    "query1 = select1 + from1 + groupby2 #+ orderby\n",
    "query1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/02 20:05:47 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: LINK_ID, LINK_POINTS, ENCODED_POLY_LINE, ENCODED_POLY_LINE_LVLS\n",
      " Schema: LinkId, LinkPoints, EncodedLinkPoints, EncodedPolyLineLvls\n",
      "Expected: LinkId but found: LINK_ID\n",
      "CSV file: file:///Users/minoseah629/Downloads/DOT_Traffic_Speeds_NBE.csv\n",
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+-----------------+\n",
      "| LINKID|          LINKPOINTS|   EncodedLinkPoints| EncodedPolyLineLvls|count(LinkPoints)|\n",
      "+-------+--------------------+--------------------+--------------------+-----------------+\n",
      "|4620315|40.84667,-73.9318...|uzhxFfyfbMcCbIsGf...|      BBBBBBBBBBBBBB|            31919|\n",
      "|4616337|40.74047,-74.0092...|}btwFx\\\\\\\\\\\\|ubMs...|       BBBBBBBBBBBBB|            32375|\n",
      "|4616223|40.6756,-74.841 4...|omgwFfhtbMeDnAaDb...|    BBBBBBBBBBBBBBBB|             5080|\n",
      "|4616203|40.52581,-74.2303...|iejvF\\\\\\\\\\\\\\\\\\\\\\\\...|     BBBBBBBBBBBBBBB|             6358|\n",
      "|4616259|40.7279205,-73.83...|otqwFbosaMlEuBbBm...|BBBBBBBBBBBBBBBBB...|             9186|\n",
      "|4620315|40.84667,-73.9318...|uzhxFfyfbMcCbIsGf...|      BBBBBBBBBBBBBB|             5676|\n",
      "|4616210|40.63092,-74.1459...|gv~vF~rpcMhF@bE[b...|BBBBBBBBBBBBBBBBB...|            84058|\n",
      "|4616202|40.56058,-74.1995...|s~pvFjb{cMfGtHxCr...|      BBBBBBBBBBBBBB|             5372|\n",
      "|4616215|40.52561,-74.2303...|adjvF\\\\\\\\\\\\\\\\\\\\|b...|          BBBBBBBBBB|             9185|\n",
      "|4620298|40.8462505,-73.93...|axhxF~zfbMkCfHeHf...|      BBBBBBBBBBBBBB|            25317|\n",
      "|4616216|40.63089,-74.1456...|av~vFpqpcMxE?`EYz...|BBBBBBBBBBBBBBBBB...|             5745|\n",
      "|4616320|40.7894406,-73.78...|_u}wFhkjaMr@dI~A~...|BBBBBBBBBBBBBBBBB...|            25617|\n",
      "|4616197|40.6210105,-74.16...|ix\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\...|               BBBBB|             4984|\n",
      "|4616320|40.7894406,-73.78...|_u}wFhkjaMr@dI~A~...|BBBBBBBBBBBBBBBBB...|             5072|\n",
      "|4616259|40.7279205,-73.83...|otqwFbosaMlEuBbBm...|BBBBBBBBBBBBBBBBB...|             5745|\n",
      "|4616350|40.74877,-73.7389...|yvuwFlcaaMzC}EbD}...|BBBBBBBBBBBBBBBBB...|             5744|\n",
      "|4616299|40.7624804,-73.83...|olxwFdwtaMpBu@jAg...|BBBBBBBBBBBBBBBBB...|             6762|\n",
      "|4456511|40.745726,-73.973...|wcuwF|}nbMTkB?qAw...|         BBBBBBBBBBB|           184408|\n",
      "|4620298|40.8462505,-73.93...|axhxF~zfbMkCfHeHf...|      BBBBBBBBBBBBBB|            82935|\n",
      "|4616203|40.52581,-74.2303...|iejvF\\\\\\\\\\\\\\\\\\\\\\\\...|     BBBBBBBBBBBBBBB|             5619|\n",
      "+-------+--------------------+--------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "linkpoints = spark.sql(query1)\n",
    "linkpoints.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/02 20:07:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: LINK_ID, LINK_POINTS, ENCODED_POLY_LINE, ENCODED_POLY_LINE_LVLS\n",
      " Schema: LinkId, LinkPoints, EncodedLinkPoints, EncodedPolyLineLvls\n",
      "Expected: LinkId but found: LINK_ID\n",
      "CSV file: file:///Users/minoseah629/Downloads/DOT_Traffic_Speeds_NBE.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1868"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkpoints.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/02 20:08:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: LINK_ID, LINK_POINTS, ENCODED_POLY_LINE, ENCODED_POLY_LINE_LVLS\n",
      " Schema: LinkId, LinkPoints, EncodedLinkPoints, EncodedPolyLineLvls\n",
      "Expected: LinkId but found: LINK_ID\n",
      "CSV file: file:///Users/minoseah629/Downloads/DOT_Traffic_Speeds_NBE.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "linkpoints.write.format('csv').mode('overwrite').save('file:/Users/minoseah629/Desktop/ait614/linkpoint1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
